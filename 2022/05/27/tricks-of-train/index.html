<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Spring's Idea" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="很多时候，外界同学管深度学习算法工程师叫做调参工程师，简单直接的概括了深度学习工程师的工作，搞深度学习的同学自己也经常自嘲，称自己的工作是炼丹，的确，深度学习模型有时候确实很奇妙，而调参在一个模型的优化中起着至关重要的作用，正因为如此，也有越来越多的研究放在了调参这件事上，比如：学习率的优化算法，模型初始化算法等等。其实，拿一个别人已经训练好的模型（比如ImageNet上预训练的ResNet），">
<meta property="og:type" content="article">
<meta property="og:title" content="Bag of Tricks for Image Classification with Convolutional Neural Networks">
<meta property="og:url" content="https://www.wanglichun.tech/2022/05/27/tricks-of-train/index.html">
<meta property="og:site_name" content="Spring&#39;s Idea">
<meta property="og:description" content="很多时候，外界同学管深度学习算法工程师叫做调参工程师，简单直接的概括了深度学习工程师的工作，搞深度学习的同学自己也经常自嘲，称自己的工作是炼丹，的确，深度学习模型有时候确实很奇妙，而调参在一个模型的优化中起着至关重要的作用，正因为如此，也有越来越多的研究放在了调参这件事上，比如：学习率的优化算法，模型初始化算法等等。其实，拿一个别人已经训练好的模型（比如ImageNet上预训练的ResNet），">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?y=\gamma&amp;space;\widehat{x}+\beta">
<meta property="og:image" content="https://www.wanglichun.tech/1.PNG">
<meta property="og:image" content="https://www.wanglichun.tech/2.PNG">
<meta property="og:image" content="https://www.wanglichun.tech/3.PNG">
<meta property="og:image" content="https://www.wanglichun.tech/4.PNG">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\eta&amp;space;_{n}=\frac{1}{2}(1+cos(\frac{t\pi&amp;space;}{T}))\eta">
<meta property="og:image" content="https://www.wanglichun.tech/5.PNG">
<meta property="og:image" content="https://www.wanglichun.tech/6.PNG">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?l=(p,softmax(z))+T^{2}l(softmax(r/T),softmax(z/T))">
<meta property="og:image" content="https://www.wanglichun.tech/7.PNG">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\widehat{x}=\lambda&amp;space;x_i+(1-\lambda&amp;space;)x_j&amp;space;,&amp;space;\widehat{y}=\lambda&amp;space;y_i+(1-\lambda&amp;space;)y_j">
<meta property="og:image" content="https://www.wanglichun.tech/8.PNG">
<meta property="og:image" content="https://www.wanglichun.tech/9.PNG">
<meta property="og:image" content="https://www.wanglichun.tech/10.PNG">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/87675bbbly1fzlf1xibwij20is0fhdh5.jpg">
<meta property="article:published_time" content="2022-05-27T05:14:50.000Z">
<meta property="article:modified_time" content="2020-02-15T19:31:28.000Z">
<meta property="article:author" content="Spring Wang">
<meta property="article:tag" content="Tricks">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://latex.codecogs.com/gif.latex?y=\gamma&amp;space;\widehat{x}+\beta">

<link rel="canonical" href="https://www.wanglichun.tech/2022/05/27/tricks-of-train/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Bag of Tricks for Image Classification with Convolutional Neural Networks | Spring's Idea</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f5aa4ee55174bece95c607a5becef769";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Spring's Idea</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-fw fa-sitemap"></i>站点地图</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.wanglichun.tech/2022/05/27/tricks-of-train/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.png">
      <meta itemprop="name" content="Spring Wang">
      <meta itemprop="description" content="众里寻他千百度，蓦然回首，那人却在灯火阑珊处">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Spring's Idea">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Bag of Tricks for Image Classification with Convolutional Neural Networks
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-05-27 13:14:50" itemprop="dateCreated datePublished" datetime="2022-05-27T13:14:50+08:00">2022-05-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-16 03:31:28" itemprop="dateModified" datetime="2020-02-16T03:31:28+08:00">2020-02-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Classification/" itemprop="url" rel="index">
                    <span itemprop="name">Classification</span>
                  </a>
                </span>
            </span>

          
            <span id="/2022/05/27/tricks-of-train/" class="post-meta-item leancloud_visitors" data-flag-title="Bag of Tricks for Image Classification with Convolutional Neural Networks" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/05/27/tricks-of-train/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/05/27/tricks-of-train/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <html><head></head><body></body></html><html><head></head><body><blockquote>
<p>很多时候，外界同学管深度学习算法工程师叫做<strong>调参工程师</strong>，简单直接的概括了深度学习工程师的工作，搞深度学习的同学自己也经常自嘲，称自己的工作是<strong>炼丹</strong>，的确，深度学习模型有时候确实很奇妙，而<strong>调参</strong>在一个模型的优化中起着至关重要的作用，正因为如此，也有越来越多的研究放在了<strong>调参</strong>这件事上，比如：学习率的优化算法，模型初始化算法等等。<br>其实，拿一个别人已经训练好的模型（比如ImageNet上预训练的ResNet），直接在自己的数据集上进行finetune，不需要怎么调参，一般都会得到不错的效果，这就是站在巨人的肩膀上，但是如果想继续提高模型的精度，该怎么做？继续调参？还是有一些其他的方法可以采用？<strong>本篇文章就介绍了Amazon工程师总结的分类模型的调参技巧。</strong></p>
</blockquote>
<hr>
<p><strong>论文名称：Bag of Tricks for Image Classification with Convolutional Neural Networks</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.01187.pdf">论文链接：https://arxiv.org/pdf/1812.01187.pdf</a></strong></p>
<hr>
<p><strong>下面直接上重点，正文开始</strong></p>
<h4 id="参数的优化方法"><a href="#参数的优化方法" class="headerlink" title="参数的优化方法"></a><strong>参数的优化方法</strong></h4><p>证明方法有效的最直接方法就是跟其他方法的效果最做对比，要对比当然就需要有一个baseline，这里就利用最常用的深度学习模型训练方法先训练一个base model，如下：</p>
<hr>
<ul>
<li><strong>训练数据预处理</strong>：</li>
</ul>
<ol>
<li>随机旋转一个batch的图像，然后将其编码成32位浮点数[0-255]。</li>
<li>随机截取一个长宽比在[3/4,4/3]的矩形，矩形面积占图像面积的[0.8,1],截取后将图像resize到224*224。</li>
<li>按照0.5的比例进行水平翻转。</li>
<li>对亮度，色度，饱和度进行跳帧。</li>
<li>增加PCA噪声，噪声分布为正态分布(0,0.1)。</li>
<li>对图像像素，减均值[123.68,116.779,103.939]，除标准差[58.393,57.12,57.375]。</li>
</ol>
<ul>
<li><strong>验证数据</strong>：</li>
</ul>
<ol start="7">
<li>短边缩放到256</li>
<li>中间截取224*224</li>
<li>对图像像素，减均值[123.68,116.779,103.939]，除标准差[58.393,57.12,57.375]</li>
</ol>
<ul>
<li><strong>参数初始化</strong></li>
</ul>
<ol start="10">
<li>卷积层以及全连接层采用Xavier算法进行初始化。</li>
<li>bn层，$\gamma=1$,$\beta=0$</li>
</ol>
<ul>
<li><strong>参数优化方法</strong></li>
</ul>
<ol start="12">
<li>梯度采用带动量的梯度优化方法：Nesterov Accelerated Gradient</li>
<li>学习率：初始学习率0.1，每30个epoch学习率下降为原来的10%</li>
<li>batchsize:256</li>
</ol>
<hr>
<p><strong>上面是最常用的深度学习模型的参数设置，作者将其作为模型的baseline，基础有了，下面我们来谈谈如何提升模型效果：</strong></p>
<h5 id="batch-size是不是越大越好？"><a href="#batch-size是不是越大越好？" class="headerlink" title="batch size是不是越大越好？"></a><strong>batch size是不是越大越好？</strong></h5><p>增加batch size可以增加网络的并行度，降低通信消耗，但是使用大的batch size同样也会带来一定的问题，比如：凸优化问题，<strong>随着batch size的增加，会增加数据的收敛的难度</strong>，换句话说，相同的epoch，使用大的batch size相比较使用小的batch size，小的batch size可能精度会更高一点。</p>
<p><strong>那么我们是不是不该使用大的batch size，当然不是，下面介绍几种方法:</strong></p>
<h5 id="方法一：线性改变学习率"><a href="#方法一：线性改变学习率" class="headerlink" title="方法一：线性改变学习率"></a><strong>方法一：线性改变学习率</strong></h5><p>在梯度下降中，由于选择的sample是随机的，所以其梯度下降的方向也是随机的，当提高batch size之后，并不能改变这种随机性，但是由于图像数量的增加，却可以中和掉一部分的噪声，所以这个时候，我们可以增加一部分的学习率，使得学习的步子迈的大一点，比如，在resnet50中，batch size=256,我们选择了lr=0.1，当batchsize增大到b的时候，lr可以调整为$0.1b/256$</p>
<h5 id="方法二：学习率预热"><a href="#方法二：学习率预热" class="headerlink" title="方法二：学习率预热"></a><strong>方法二：学习率预热</strong></h5><p>当我们开始训练模型的时候，往往模型的参数都是随机初始化的，并不能代表什么，所以如果此时选择一个较大的学习率，往往会导致模型的不稳定，那么什么是学习率预热，简单来说就是先使用一个较小的学习率，先迭代几个epoch，等到模型基本稳定的时候再用初始设置的学习率进行训练。举个例子，比如预热5个epoch，学习率设置成lr，则前5个epoch可以设置学习率线性递增，即第一个epoch：0.2*lr,第二个:0.4*epoch,依次类推，到第五个变为lr。</p>
<h5 id="方法三：部分BN层r-gamma-设置成0"><a href="#方法三：部分BN层r-gamma-设置成0" class="headerlink" title="方法三：部分BN层r(gamma)设置成0"></a><strong>方法三：部分BN层r(gamma)设置成0</strong></h5><p>resnet我们都知道，中间有很多BN层，BN层的提出可以说是模型训练的一个里程碑，它使得模型的训练更加简单，模型收敛更加快速，并且可以使用更大的学习率进行训练，BN层的作用就是对数据进行归一化操作，然后通过设置两个学习参数对归一化进行调整，即：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=y=\gamma&amp;space;\widehat{x}+\beta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y=\gamma&amp;space;\widehat{x}+\beta" title="y=\gamma \widehat{x}+\beta"></a></p>
<p>其中$\gamma$以及$\beta$是可以学习的，$\widehat{x}$是对输入进行标准化的结果，通常的做法是将$\gamma$初始化为1，$\beta$初始化为0，这里作者建议在使用resnet的时候，将每个block的最后的BN层的$\gamma$初始化为0，这样无论前面的结果如何，经过这一层都被清零了，block的输出就只有前面的short cut部分，导致每个block的输入都是一样的，作者解释说，这样可以使得网络的训练更加的方便。</p>
<h5 id="方法四：不使用bias-decay"><a href="#方法四：不使用bias-decay" class="headerlink" title="方法四：不使用bias decay"></a><strong>方法四：不使用bias decay</strong></h5><p>在深度学习训练中，decay是一个很好的策略，可以防止参数多大引起过拟合，一般常采用的策略是L2范数，这里作者建议在做decay的时候，只对卷基层以及全连接层的weight加入decay就可以了，不需要对bias进行处理。</p>
<h5 id="方法五：低精度训练"><a href="#方法五：低精度训练" class="headerlink" title="方法五：低精度训练"></a><strong>方法五：低精度训练</strong></h5><p>目前的GPU训练基本是采用32位浮点数进行数据存储的，即FP32,但是新的GPU比如Nvidia V100,支持16为浮点数的运行，速度可以提升2-3倍，而且采用更大的batchsize后（当然使用了前面的各种策略来配合batchsize的提升），精度还小有提升。如下面Table3所示。</p>
<p><img src="/1.PNG"></p>
<p>当然，哪步更有用作者同样给了分析，如下表Table 4，可见，Zero $\gamma$带来的精度提升是最大的。</p>
<p><img src="/2.PNG"></p>
<h4 id="网络的优化方法"><a href="#网络的优化方法" class="headerlink" title="网络的优化方法"></a><strong>网络的优化方法</strong></h4><p><img src="/3.PNG"></p>
<p>对于resnet结构，我们应该都不陌生，如果不了解可以查看博客:<a target="_blank" rel="noopener" href="https://blog.csdn.net/Chunfengyanyulove/article/details/79253656">ResNet(Deep Residual Learning for Image Recognition)</a><br>在网络设计中，设计模型结构是最难的，下面介绍几个比较成熟的技巧：</p>
<ul>
<li>ResNet B:</li>
</ul>
<p>由于在ResNet中，每个stage的第一个block会进行图像尺度的缩小，采用了如图Figure1 深蓝色那部分结构，首先是1*1卷积层，stride=2，使得网络的feature map缩小一半，然后再经过3*3的卷积层，但是stride=2的1*1的卷积层会带来一个问题，会损失掉一半的信息（这里论文中提到是3/4），ResNet B修改了这个结构，将stride=2放到了3*3的卷积，这样就不会带来信息的损失了。</p>
<ul>
<li>ResNet C:</li>
</ul>
<p>使用3个3*3的卷积来替换resnet的7*7的卷积。并且前2个卷积的stride=3,channel=32,最后一个channel=64，这是一个比较老的套路了，在inception网络中被提出。</p>
<ul>
<li>ResNet D:</li>
</ul>
<p>既然主通道可以通过修改stride来降低信息损失，那么short cut为什么不可以呢？当然可以，作者是怎么做的呢？首先增加了一个2*2的average pooling layer， 设置stride=2，conv层的stride变为1。</p>
<p><strong>对比一下这几个结构的精度,resnet B的提升是最有效的，相对提升了约0.5个百分点resnet C以及resnet D分别又提升了0.2%以及0.3%，整体大约提升了1个百分点。</strong></p>
<p><img src="/4.PNG"></p>
<h4 id="模型的训练技巧"><a href="#模型的训练技巧" class="headerlink" title="模型的训练技巧"></a><strong>模型的训练技巧</strong></h4><h5 id="技巧一-cosine-learning-rate-decay："><a href="#技巧一-cosine-learning-rate-decay：" class="headerlink" title="技巧一  : cosine learning rate decay："></a>技巧一  : cosine learning rate decay：</h5><p>前面我们提到了训练模型的时候学习率需要warmup，可是在warmup之后，随着epoch的增加，学习率需要适度的调低，这就叫learning rate decay，我们常采用的方法是使用<strong>step decay</strong>,最简单的比如每20个epoch降低学习率为原来的10%，本篇综述提到了使用cosine learning rate decay，即采用cosine的方式来降低学习率，公式如下：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=\eta&amp;space;_{n}=\frac{1}{2}(1+cos(\frac{t\pi&amp;space;}{T}))\eta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\eta&amp;space;_{n}=\frac{1}{2}(1+cos(\frac{t\pi&amp;space;}{T}))\eta" title="\eta _{n}=\frac{1}{2}(1+cos(\frac{t\pi }{T}))\eta"></a></p>
<p>红色的线为采用cosine decay策略，蓝色的为采用step decay策略，可以发现，cosine decay策略更加的平滑，训练的精度提升也是逐步提升，不像step策略，会有跳跃。不过训到最后，精度基本差不多，<strong>个人觉得，step其实也挺好用。</strong></p>
<p><img src="/5.PNG"></p>
<h5 id="技巧二-Label-Smoothing"><a href="#技巧二-Label-Smoothing" class="headerlink" title="技巧二 : Label Smoothing"></a>技巧二 : Label Smoothing</h5><p>在分类算法中，我们常采用的是one-hot编码，label smoothing的策略就是在one-hot的基础上，减去一个较小的值，如下公式，作者解释到，<strong>这样可以一定程度上减少过拟合</strong>，在采用one-hot编码的时候，只需要计算label类别的损失就可以了，采用label smoothing后，不仅仅需要计算label类别的损失，还需要增加其他类别的损失，这样，在one-hot编码的时候，对应目标的输出的目标值是正无穷，这样跟其他类别的差距更大，而增加了smooth label之后，由于引入了参数$\sigma$，所以随着$\sigma$的变化，其目标发生了变化，作者也画出了其目标图，如图figure 4(a)，可见Gap基本集中在9左右，实际的实验结果如图Figure 4(b)，也证实了这一点，b也符合a中基本都集中在9左右，并且b中smooth明显要比one-hot要小一点。</p>
<p><img src="/6.PNG"></p>
<h5 id="技巧三：知识蒸馏"><a href="#技巧三：知识蒸馏" class="headerlink" title="技巧三：知识蒸馏"></a>技巧三：知识蒸馏</h5><p>知识蒸馏也是提升模型精度的一个方法，知识蒸馏中，一般有一个精度较好的model作为teacher model，利用teacher model去帮助student model训练，比如：可以采用resnet-152作为teacher model，resnet-50作为student model。在利用知识蒸馏的方法进行训练的时候，需要增加用于蒸馏的loss,举个例子，假设p是真实概率，z和r分别是student以及teacher model的全连接层的输出结果，则损失函数为：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=l=(p,softmax(z))+T^{2}l(softmax(r/T),softmax(z/T))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?l=(p,softmax(z))+T^{2}l(softmax(r/T),softmax(z/T))" title="l=(p,softmax(z))+T^{2}l(softmax(r/T),softmax(z/T))"></a></p>
<p>这里解释一下这个T(蒸馏温度参数)，T是一个使得softmax output更加平滑的参数，以便于student model从teacher model学习参数。</p>
<p>下图是设置不同的T(蒸馏温度)得到的值，可以看到随着T的增大，曲线便的越来越平滑，其实设置这个标签的目的就是软化标签，增加训练难度，这样在inference的时候，将T重新设置为1，有难度的时候都可以表现很好，简单模式下，这样其分类的准确性就会更高了。</p>
<p><img src="/7.PNG"></p>
<h5 id="技巧四：mixup-training"><a href="#技巧四：mixup-training" class="headerlink" title="技巧四：mixup training"></a>技巧四：mixup training</h5><p>所谓的mixup training，就是每次要取出2张图像，然后将两张图像进行线性组合，得到新的图像，以此来作为新的训练样本，进行网络的训练，如下公式，其中x代表图像数据，y代表标签，则得到的$\widehat{x}$,$\widehat{y}$则为送入网络的训练样本。</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=\widehat{x}=\lambda&amp;space;x_i+(1-\lambda&amp;space;)x_j&amp;space;,&amp;space;\widehat{y}=\lambda&amp;space;y_i+(1-\lambda&amp;space;)y_j" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\widehat{x}=\lambda&amp;space;x_i+(1-\lambda&amp;space;)x_j&amp;space;,&amp;space;\widehat{y}=\lambda&amp;space;y_i+(1-\lambda&amp;space;)y_j" title="\widehat{x}=\lambda x_i+(1-\lambda )x_j , \widehat{y}=\lambda y_i+(1-\lambda )y_j"></a></p>
<p>mixup方法主要增强了训练样本之间的线性表达，增强网络的泛化能力，并且使用mixup方法需要较长的时间收敛。</p>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p>Table 6是作者使用上面不同的方法进行的实验结果，其中w/代表的是with,w/o代表的是without，根据实验结果可以发现，在使用了cosine decay，label smooth方法，在ImageNet的结果上，基本会提高一个点左右。采用mixup方法，三个网络也基本一致的提升了，对于蒸馏的效果，resnet网络的效果提升了大约0.3%，但是对于Inception-V3以及MobileNet，精度都下降了，为什么会出现这种情况呢？原因可能是：由于这里是利用ResNet-152作为teacher model的，而ResNet-152的输出的数据分布和Inception以及mobileNet的分布不同，所以导致了结果的不一致性。</p>
<p>Table 7是作者在Places 365数据集的测试结果，结果表明，采用这几个策略进行训练的结果同样也是有效的。</p>
<p><img src="/8.PNG"></p>
<p><strong>既然我们的模型在分类任务上表现提升了，那么使用此模型，在目标检测以及目标分割上是否有用呢？</strong></p>
<p>首先作者测试了其在Faster R-CNN中的效果，测试结果如下表所示，这里，作者使用的是VGG-19作为backbone，使用不同精度的预训练模型进行训练，可以发现，在使用了精度更高的预训练模型之后，Faster R-CNN的mAP最终提高了大约4%（77.54-&gt;81.33）</p>
<p><img src="/9.PNG"></p>
<p>在图像分割方面，最具代表性的网络就是FCN，作者在FCN网络上测试了不同精度的backbone对FCN的影响，结果如下表所示，可见，采用了作者调优后的模型还是具有一定的效果的，不过这里对于采用了cosine优化的效果最佳，对于采用了label smoothing，mixup等方法效果不是特别的明显，这是为什么呢？<strong>猜想应该是图像分割是对每个像素进行分类，而采用了诸如label smoothing方法，本身对于像素的标签产生了一定的影响，采用mixup等方法直接对像素值进行了改变，进而影响了对像素分类的效果</strong>。 </p>
<p><img src="/10.PNG"></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>本篇文章是Amazon对于分类模型炼丹方法的一个总结，介绍了很多trick，还是有很多借鉴意义的，至少我现在使用的其提供的resnet模型，在分类效果上确实有一定的提升。</p>
<h4 id="彩弹"><a href="#彩弹" class="headerlink" title="彩弹"></a>彩弹</h4><p>对于Amazon这样的大公司，当然也不会只是纸上谈兵，既然讲了这么多的方法，有没有预训练模型提供给我们使用呢？当然是有的，不过由于亚马逊推的是自己的深度学习框架MXNet+Gluon,所以这些预训练模型是在最新的GluonCV的model_zoo中提供。</p>
<p>有兴趣的读者可以自行查看，网站链接如下：</p>
<p><a target="_blank" rel="noopener" href="https://gluon-cv.mxnet.io/model_zoo/classification.html">https://gluon-cv.mxnet.io/model_zoo/classification.html</a></p>
<p>并且，gluoncv中还给出了各个模型的运行时间对比，内存消耗对比等，如下图所示，方便大家根据自己的需求选择合适的模型。</p>
<p><img src="http://ww1.sinaimg.cn/large/87675bbbly1fzlf1xibwij20is0fhdh5.jpg"></p>
<p>最后附上一段使用gluoncv进行imagenet分类的代码：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> gluoncv</span><br><span class="line"></span><br><span class="line"><span class="comment"># you can change it to your image filename</span></span><br><span class="line">filename = <span class="string">'classification-demo.png'</span></span><br><span class="line"><span class="comment"># you may modify it to switch to another model. The name is case-insensitive</span></span><br><span class="line">model_name = <span class="string">'ResNet50_v1d'</span></span><br><span class="line"><span class="comment"># download and load the pre-trained model</span></span><br><span class="line">net = gluoncv.model_zoo.get_model(model_name, pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line">img = mx.image.imread(filename)</span><br><span class="line"><span class="comment"># apply default data preprocessing</span></span><br><span class="line">transformed_img = gluoncv.data.transforms.presets.imagenet.transform_eval(img)</span><br><span class="line"><span class="comment"># run forward pass to obtain the predicted score for each class</span></span><br><span class="line">pred = net(transformed_img)</span><br><span class="line"><span class="comment"># map predicted values to probability by softmax</span></span><br><span class="line">prob = mx.nd.softmax(pred)[<span class="number">0</span>].asnumpy()</span><br><span class="line"><span class="comment"># find the 5 class indices with the highest score</span></span><br><span class="line">ind = mx.nd.topk(pred, k=<span class="number">5</span>)[<span class="number">0</span>].astype(<span class="string">'int'</span>).asnumpy().tolist()</span><br><span class="line"><span class="comment"># print the class name and predicted probability</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'The input picture is classified to be'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'- [%s], with probability %.3f.'</span>%(net.classes[ind[i]], prob[ind[i]]))</span><br></pre></td></tr></tbody></table></figure>
</body></html>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Tricks/" rel="tag"># Tricks</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2022/01/06/swin/" rel="next" title="Swin">
                  <i class="fa fa-chevron-left"></i> Swin
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2022/05/27/resnet/" rel="prev" title="ResNet(Deep Residual Learning for Image Recognition)">
                  ResNet(Deep Residual Learning for Image Recognition) <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">参数的优化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#batch-size%E6%98%AF%E4%B8%8D%E6%98%AF%E8%B6%8A%E5%A4%A7%E8%B6%8A%E5%A5%BD%EF%BC%9F"><span class="nav-number">1.1.</span> <span class="nav-text">batch size是不是越大越好？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A%E7%BA%BF%E6%80%A7%E6%94%B9%E5%8F%98%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="nav-number">1.2.</span> <span class="nav-text">方法一：线性改变学习率</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%BA%8C%EF%BC%9A%E5%AD%A6%E4%B9%A0%E7%8E%87%E9%A2%84%E7%83%AD"><span class="nav-number">1.3.</span> <span class="nav-text">方法二：学习率预热</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%B8%89%EF%BC%9A%E9%83%A8%E5%88%86BN%E5%B1%82r-gamma-%E8%AE%BE%E7%BD%AE%E6%88%900"><span class="nav-number">1.4.</span> <span class="nav-text">方法三：部分BN层r(gamma)设置成0</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E5%9B%9B%EF%BC%9A%E4%B8%8D%E4%BD%BF%E7%94%A8bias-decay"><span class="nav-number">1.5.</span> <span class="nav-text">方法四：不使用bias decay</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%BA%94%EF%BC%9A%E4%BD%8E%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83"><span class="nav-number">1.6.</span> <span class="nav-text">方法五：低精度训练</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">网络的优化方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7"><span class="nav-number">3.</span> <span class="nav-text">模型的训练技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8A%80%E5%B7%A7%E4%B8%80-cosine-learning-rate-decay%EF%BC%9A"><span class="nav-number">3.1.</span> <span class="nav-text">技巧一  : cosine learning rate decay：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8A%80%E5%B7%A7%E4%BA%8C-Label-Smoothing"><span class="nav-number">3.2.</span> <span class="nav-text">技巧二 : Label Smoothing</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8A%80%E5%B7%A7%E4%B8%89%EF%BC%9A%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="nav-number">3.3.</span> <span class="nav-text">技巧三：知识蒸馏</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8A%80%E5%B7%A7%E5%9B%9B%EF%BC%9Amixup-training"><span class="nav-number">3.4.</span> <span class="nav-text">技巧四：mixup training</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">4.</span> <span class="nav-text">实验结果</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BD%A9%E5%BC%B9"><span class="nav-number">6.</span> <span class="nav-text">彩弹</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Spring Wang"
    src="/images/head.png">
  <p class="site-author-name" itemprop="name">Spring Wang</p>
  <div class="site-description" itemprop="description">众里寻他千百度，蓦然回首，那人却在灯火阑珊处</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">41</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/lichun-wang" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;lichun-wang" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/lichun_wang1993@163.com" title="E-Mail &amp;rarr; lichun_wang1993@163.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Chunfengyanyulove" title="CSDN &amp;rarr; https:&#x2F;&#x2F;blog.csdn.net&#x2F;Chunfengyanyulove" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/chunfengyanyu" title="Weibo &amp;rarr; https:&#x2F;&#x2F;weibo.com&#x2F;chunfengyanyu" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Spring Wang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v6.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.5.0
  </div>

        






  <script>
  function leancloudSelector(url) {
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = visitors.getAttribute('id').trim();
      var title = visitors.getAttribute('data-flag-title').trim();

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .then(() => {
                leancloudSelector(url).innerText = counter.time + 1;
              })
              .catch(error => {
                console.log('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.log('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return element.getAttribute('id').trim();
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.url;
            var time = item.time;
            leancloudSelector(url).innerText = time;
          }
          for (var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=Lgw7TumxtycA4MCC8Ro8gL4a-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'Lgw7TumxtycA4MCC8Ro8gL4a-gzGzoHsz',
            'X-LC-Key': 'VAwpszUEpH7osEG3O76jh3be',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        const localhost = /http:\/\/(localhost|127.0.0.1|0.0.0.0)/;
        if (localhost.test(document.URL)) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>






        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'Lgw7TumxtycA4MCC8Ro8gL4a-gzGzoHsz',
    appKey: 'VAwpszUEpH7osEG3O76jh3be',
    placeholder: "comments",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

</body>
</html>
